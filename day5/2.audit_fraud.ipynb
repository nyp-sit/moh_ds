{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/nyp_ago_logo.png\" width='400'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ft1ZxspklJfx"
   },
   "source": [
    "# Predict Fraudulent Firm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qRmmiyaZtn0"
   },
   "source": [
    "In this exercise, we will try to build a classification model that can help auditor to predict the fraudulent firm on the basis of present and historical risk factors\n",
    "\n",
    "The following dataset is based on the research work done as a case study of an external government audit company which is also the external auditor of government firms of India. During audit-planning, auditors examine the business of different government offices. There are total 777 firms data from 46 different cities of a state that are listed by the auditors for targeting the next field-audit work. \n",
    "\n",
    "Below is partial description of the differenet columns in the dataset (many description are missing for the various columns in the Kaggle site as well as the original UCI Machine Learning Repository)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Field|Description|\n",
    "|----|----|\n",
    "|Sector_score|Historical risk score value of the target-unit using analytical procedure|\n",
    "|LOCATION_ID|Unique ID of the city/province|\n",
    "|PARA_A|Discrepancy found in the planned expenditure of inspection and summary report A in Rs (in crore)|\n",
    "|PARA_B|Discrepancy found in the unplanned expenditure of inspection and summary report B in Rs (in crore)|\n",
    "|Total|Total amount of discrepancy found in other reports Rs (in crore)|\n",
    "|numbers|Historical discrepancy score|\n",
    "|Money_Value|Amount of money involved in misstatements in the past audits|\n",
    "|Audit_Risk|Total risk score using analytical procedure|\n",
    "|Risk|Risk class assigned to an audit-case (Target feature)|\n",
    "\n",
    "\n",
    "1. Sector_score- Historical risk score value of the target-unit using analytical procedure\n",
    "2. LOCATION_ID- Unique ID of the city/province.\n",
    "3. PARA_A- Discrepancy found in the planned expenditure of inspection and summary report A in Rs (in crore).\n",
    "4. PARA_B- Discrepancy found in the unplanned expenditure of inspection and summary report B in Rs (in crore).\n",
    "5. TOTAL- Total amount of discrepancy found in other reports Rs (in crore).\n",
    "6. numbers- Historical discrepancy score\n",
    "7. Money_Value- Amount of money involved in misstatements in the past audits.\n",
    "8. Audit_Risk- Total risk score using analytical procedure\n",
    "9. Risk- Risk Class assigned to an audit-case. (Target label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TpQg8R9QUplX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import  accuracy_score, f1_score, precision_score,confusion_matrix, recall_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGorNXkCOvGU"
   },
   "source": [
    "## Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5UKpQS91lZlp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/audit_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out some information about the data, such the columns and its datatype. We can see that all columns are numeric except the LOCATION_ID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Are there any missing values? Write code to check for missing value and if so, how should we handle this missing value? \n",
    "\n",
    "<details><summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "df.isna().sum()\n",
    "df.dropna(axis=0, inplace=True)\n",
    "```\n",
    "<br/>\n",
    "There is missing value for the Money_Value column. There are few ways to handle missing value, e.g. throw away the row that contains the missing value, or throw away the column that has the missing value, or impute the missing value.  In this case, since we only have one missing value for one record, we should not throw away the entire column.  We can either throw away the row (record) or impute the value. In our case, we just throw away the record.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Write code here \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Before we start our EDA, it is good practice to set aside a test set, so that we only perform EDA on the train set, to prevent any 'data snooping'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, stratify=df['Risk'], random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uawZTD7GuesA"
   },
   "source": [
    "**Exercise**\n",
    "\n",
    "Let's plot the distribution of the target label 'Risk'. Is there any obvious class imbalance?\n",
    "\n",
    "<p>\n",
    "<details><summary>Click here for answer</summary>\n",
    "\n",
    "```python\n",
    "sns.countplot(x = df['Risk'], label = \"Count\")\n",
    "```\n",
    "<br/>\n",
    "\n",
    "There are 471 non-risk vs 305 risk class, so the data is not really imbalanced. \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQ602zPgoSBE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Complete the code \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One quick way to get a feel of the type of data you are dealing with is to plot a histogram for each numerical attribute. You can do so using the hist() method on the panda dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_features = df_train.copy().drop('Risk', axis=1)\n",
    "df_features.hist(bins=50, figsize=(14, 10))\n",
    "plt.rc('font', size=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** \n",
    "\n",
    "What do you notice about the 'Detection_Risk'?  Write code to confirm your observation.\n",
    "\n",
    "<details><summary>Click here for solution</summary>\n",
    "<br/>\n",
    "The 'Detection_Risk' seems to only have one. To confirm it, we can use value_counts() to find out.\n",
    "<br/>\n",
    "<br/>\n",
    "    \n",
    "```python\n",
    "df_features['Detection_Risk'].value_counts()\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Complete the code \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there any redundant feature? \n",
    "\n",
    "From the description of the dataset, it is said that the TOTAL column is the total amount of discrepancy found in other reports PARA_A and PARA_B. This will introduce multicollinearity in our model and should be avoided. Let's find out if this is the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first create a column 'TOTAL_2' that is the sum of both PARA_A and PARA_B values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_features['TOTAL_2'] = df[['PARA_A', 'PARA_B']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out those rows which have different TOTAL from the sum of PARA_A and PARA_B (i.e. TOTAL_2). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_features.loc[(df_features['TOTAL_2'] != df_features['TOTAL'])][['TOTAL', 'TOTAL_2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you observe?  Seems that there are total of 106 rows that have different TOTAL and TOTAL_2.  But on closer look, they have the same values!! What happened? \n",
    "Turn out that comparing two floating point values are problematic due to internal precision error when representing floating number. We can round the floating point numbers to certain fixed number of precision using `df.round()` and then compare them or we can use `np.isclose()`. \n",
    "\n",
    "Let's compare again after rounding the TOTAL and TOTAL_2 to 9 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_features.loc[(df_features['TOTAL_2'].round(9) != df_features['TOTAL'].round(9))][['TOTAL', 'TOTAL_2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We see that we only 2 rows that are gives a different total. This may be due to data entry error. We can go ahead and drop 'TOTAL' without much problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Check correlation\n",
    "\n",
    "**Exercise** \n",
    "\n",
    "We can try to find out how the (numerical) features correlate with the target, by using Pearson coefficient. This can be done with panda dataframe `corrwith()`. \n",
    "Sort the correlation coefficients in descending order.\n",
    "\n",
    "<details><summary>Click here for solution</summary>\n",
    "\n",
    "```python \n",
    "\n",
    "df.corrwith(df['Risk']).sort_values(ascending=False)\n",
    "df_train.corrwith(df_train['Risk']).sort_values(ascending=False).plot.bar(title=\"Correlation with Risk\", figsize=(9, 6))\n",
    "```\n",
    "</details>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Complete the code \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are not usig Machine Learning, can we come up with a quick and simple rule-based classifier that predict the risk class of a firm (0 or 1)? \n",
    "\n",
    "From the correlation analysis above, we can see that the Score is most highly correlated with Risk (more than 0.78).  We can derive a simple rule-base classifier based just on the Score. If it exceeds certain threshold, then it is 'Risk', else it is 'No Risk'.  But how do we determine the threshold. To do this, it will be useful to look at how the values of Score is distributed for both 'Risk' class nad 'No Risk' class.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores_Risk = df_train.loc[ df_train['Risk'] == 1 ].Score\n",
    "scores_NoRisk = df_train.loc[ df_train['Risk'] == 0 ].Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('\\nScores (Risk):\\n', scores_Risk.describe())\n",
    "print('\\nScores (No Risk):\\n', scores_NoRisk.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use boxplot to more easily identify the distribution of both Scores (Risk vs No Risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.boxplot([scores_Risk, scores_NoRisk])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** \n",
    "\n",
    "What Score value should we use as a threshold to decide which is 'Risk' and 'No Risk'? Write code to determine the accuracy score for the selected threshold. \n",
    "\n",
    "<details><summary>Click here for solution</summary>\n",
    "<br/>\n",
    "    \n",
    "```python\n",
    "thresholds = [2.2, 2.3, 2.4, 2.5]\n",
    "\n",
    "for threshold in thresholds: \n",
    "    preds = (df_test['Score'] >= threshold)\n",
    "    acc = accuracy_score(df_test['Risk'], preds)\n",
    "    print(f'accuracy score [threshold = {threshold}: {acc}')\n",
    "```\n",
    "\n",
    "<br/>\n",
    "Based on the result, threshold of 2.3 and 2.4 give the highest accuracy score of 0.88)\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Complete the code \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** \n",
    "\n",
    "Instead of just using 'Score', we can also combine the value of other highly-correlated features such as 'Score_MV', 'Score_A', 'Score_B'.\n",
    "Can you write the code to combine the values of these other features (e.g. use either `sum()` or `mean()`) and derive a threshold to use as a rule. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score attained by using simple rule-based comparison should be the baseline accuracy. Our ML should perform better than this baseline for it to be worthwhile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are done with our EDA.  Based on our EDA above, we can drop the columns \"LOCATION_ID\", \"Detection_Risk\" and \"TOTAL\". \n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Complete the code below to:\n",
    "\n",
    "1. Drop the above-mentioned columns \n",
    "2. Split the dataset with stratified split\n",
    "3. Scale the train set as well as test set.\n",
    "\n",
    "<details><summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "df_prepared = df.drop(['LOCATION_ID', 'Detection_Risk', 'TOTAL'], axis=1)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Complete the code \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOEBkOVmqoke",
    "tags": []
   },
   "source": [
    "### Feature Scaling \n",
    "\n",
    "**Exercise:** Apply standard scalar on the data.\n",
    "\n",
    "Hints: Use `fit_transform()` on training data and use `transform` on testing data.\n",
    "\n",
    "<p>\n",
    "<details><summary>Click here for answer</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(sc_X.fit_transform(X_train))\n",
    "X_test_scaled = pd.DataFrame(sc_X.transform(X_test))\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iz7L7JjQqsQ1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Complete the code here \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we are ready to train our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4V5uk1t8rgdo"
   },
   "source": [
    "**Exercise**\n",
    "\n",
    "We will first see how well a logistic regression model perform on our data by using Cross Validation, since our data is quite small.\n",
    "\n",
    "<p>\n",
    "<details><summary>Click here for answer</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "logi = LogisticRegression()\n",
    "logi.fit(X_train_scaled, y_train)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OCsY3wfyrAzf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Complete the code \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the cross-validation accuracy scores, seems that our Logistic Regression (LR) model is pretty good. We will now train the LR using our full train set.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Complete the code to train the LR with full X_train set and print the classification report on the X_test set. \n",
    "\n",
    "<details><summary>Click here for solution</summary>\n",
    "<br/>\n",
    "\n",
    "```python\n",
    "lg_clf.fit(X_train, y_train)\n",
    "y_preds = lg_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_preds))\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Complete the code \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUQw4-BcyrON"
   },
   "source": [
    "**Exercise:** \n",
    "\n",
    "Try to train another model using DecisionTreeClassifier. set the max_depth=3 to avoid overfitting. \n",
    "<p>\n",
    "<details><summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "dt_clf = DecisionTreeClassifier(max_depth=3)\n",
    "cross_val_score(dt_clf, X = X_train_scaled, y = y_train, cv=5, scoring = 'accuracy').mean()\n",
    "dt_clf.fit(X_train, y_train)\n",
    "y_preds = dt_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_preds))\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7lfcjjwxrBYe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Complete the code below\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
