{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEUHCkORI-TF"
   },
   "source": [
    "<img src=\"https://nyp-aicourse.s3.ap-southeast-1.amazonaws.com/agods/nyp_ago_logo.png\" width='400'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOPaMUiqI-TI"
   },
   "source": [
    "# Introduction to ordinary least squares (OLS) Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XH3PtUidI-TJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FV_2hT0LI-TM"
   },
   "source": [
    "# Survey Data\n",
    "We will use this [simple survey data](https://stats.idre.ucla.edu/wp-content/uploads/2016/02/p054.txt) to demonstrate a few basic features of ***statsmodels*** and ***seaborn*** and how they might be used in a data science workflow for regression.\n",
    "\n",
    "The dataset is simply the results of a survey where the question responses are all numeric.  This leads to 6 numeric independent variable (predictor or feature) fields and 1 numeric dependent variable (response or target) field.  The predictors are labeled ***X<sub>i</sub>*** and the response is labeled ***Y***.\n",
    "\n",
    "Load the dataset in using ***pandas*** and take a look at it.  Here we use [***pandas.read_table***](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_table.html) to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDcH4qnsI-TN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_table('data/p054.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p5IuSSdRYVAy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take a look at the datatypes\n",
    "#Add code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JTXJUKNWI-TN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take a look at the first few rows\n",
    "#Add code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "br77QcroI-TO"
   },
   "source": [
    "If we look at the column names, we will notice the trailing whitespace problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jGPSMkqiI-TO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Add code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxJ7jvviI-TO"
   },
   "source": [
    "We can remove this by calling map on the columns list and stripping the whitespace with strip.  The ***map*** function is applied to Series objects, whereas the ***apply*** and ***applymap*** functions are called on Dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AAspgcwCI-TO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.columns = df.columns.map(str.strip)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQTwXBNnI-TP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# How many rows and columns does the dataset have?\n",
    "#Add code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnuITL6dI-TP"
   },
   "source": [
    "### Visualizing with Seaborn\n",
    "We see that the data has 30 responses with 7 fields (6 independent, 1 dependent) each.  Let's use pandas to check out the correlations between the different variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6bmGUlZMI-TP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# View the correlations\n",
    "#Add code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2nyiVg_I-TP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use seaborn heatmap for a better visualisation\n",
    "sns.heatmap(df.corr(), cmap=\"seismic\", annot=True, vmin=-1, vmax=1);\n",
    "\n",
    "# more cmaps: https://matplotlib.org/examples/color/colormaps_reference.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPHIe5K2I-TQ"
   },
   "source": [
    "### Correlation and Multicollinearity\n",
    "We notice that some of the variables are highly correlated. When 2 predictor variables (i.e. features) are highly correlated this is called [multicollinearity](https://en.wikipedia.org/wiki/Multicollinearity) and it is something we want to watch out for as it can destabilize our model.  In the extreme case, when 2 features are perfectly correlated then there is absolutely nothing gained by making both variables part of our regression.\n",
    "\n",
    "The other takeaway from this table is that some of our features are highly correlated with our ***target variable Y***.  This is a good thing, it means that these are the variables that we most likely want to include as part of our model as they explain a large amount of the variance in the target variable (correlation=R, variance_explained=R<sup>2</sup>).\n",
    "\n",
    "Let's try to visualize these correlations all together by using the [***seaborn pairplot***](http://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.pairplot.html) function.\n",
    "\n",
    "> What do you notice?\n",
    "> Almost all correlations are positive, somewhat normal distributions, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQeUaKVyI-TQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot all of the variable-to-variable relations as scatterplots\n",
    "sns.pairplot(df, height=1.2, aspect=1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sr-M16VHI-TQ"
   },
   "source": [
    "### Ordinary Least Squares Regression with Statsmodels\n",
    "Now that we have a feel for our data, let's try to build a basic regression model.  \n",
    "\n",
    "#### Statsmodels\n",
    "We are going to use the [**`statsmodels`**](http://statsmodels.sourceforge.net/) library first.  `statsmodels` is a Python package for implementing [**linear models**](https://en.wikipedia.org/wiki/Linear_model), of which **Linear Regression** is one.  It has a bunch of nice features for evaluating and executing such models.\n",
    "\n",
    "#### Modeling with Statsmodels\n",
    "There are 2 main ways you can generate models with stats models:\n",
    "- Via the `statsmodels.api` package\n",
    "- Via the `statsmodels.formula.api` package\n",
    "\n",
    "For both approaches, you will need somewhere to use the [R formula](http://science.nature.nps.gov/im/datamgmt/statistics/r/formulas/) styles formulas for defining the relationship between target variable and feature variables in your model.  ***Statsmodels*** uses [***patsy***](http://patsy.readthedocs.org/en/latest/) to convert this syntax into the proper data matrices for input into its linear models under the covers.  There are a variety of interactions and functions of variables that you can incorporate with this syntax, so feel free to check out the docs.\n",
    "\n",
    "**Model 1 - 6 features**\n",
    "\n",
    "Here we'll just start by defining a regression model that takes as its inputs each of the 6 predictor variables.  The other parameter of course is the data that the model is to be built from, our pandas dataframe.\n",
    "\n",
    "This first model fitting is done for you, it fits a multiple linear regression model of the following form:\n",
    "\n",
    "$$\n",
    "\\hat{Y} = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\beta_3X_3 + \\beta_4X_4 + \\beta_5X_5 + \\beta_6X_6\n",
    "$$\n",
    "\n",
    "##### `statsmodels.api`\n",
    "To use this method, you need to generate a **matrix** of **features**, **`X`** and a **vector** of **targets**, **`y`** where each row represents a single **observation**.  In statsmodels, you can do this with a call to **`patsy.dmatrices`**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WwOfF6WTI-TR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create your feature matrix (X) and target vector (y)\n",
    "y, X = patsy.dmatrices('Y ~ X1 + X2 + X3 + X4 + X5 + X6', data=df, return_type=\"dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TkXUqwIsI-TR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#display y first 5 rows\n",
    "#Add code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qwe_EvOSI-TR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#display X fisrt 5 rows\n",
    "#Add code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zBJSvRe8I-TR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create your model\n",
    "model = sm.OLS(y, X)\n",
    "\n",
    "# Fit your model to your training set\n",
    "fit = model.fit()\n",
    "\n",
    "# Print summary statistics of the model's performance\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i51Q8nW-I-TS"
   },
   "source": [
    "## Regression Statistics\n",
    "\n",
    "***R<sup>2</sup>*** is the square of the correlation coefficient and represents the estimated percentage of the variance in our target variable ***Y*** that can be explained by our regression model.  \n",
    "\n",
    "***Adjusted R<sup>2</sup>*** also penalizes for things such as large coefficients and extra variables to try and limit ***overfitting*** so it is often a better measure of model efficacy.\n",
    "\n",
    "The middle table provides the **coefficients** that regression has found, along with the **standard error** for each coefficient. This defines our model, i.e. these are the model parameters that our algorithm was seeking to determine.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anG16EWJI-TS"
   },
   "source": [
    "**Model 2 - 3 features**\n",
    "\n",
    "Putting it all together, the final column returns a **95% Confidence Interval** for the value of each coefficient.\n",
    "\n",
    "Given these stats, lets remove the highest 3 P-values (low p-values are optimal) from our regression model, from ***X<sub>2</sub>***, ***X<sub>4</sub>***, and ***X<sub>5</sub>*** and see how our model performs now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHra4-qdI-TS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model without X2, X4, and X5\n",
    "lm2 = smf.ols('Y ~ X1 + X3 + X6', data=df)\n",
    "\n",
    "# Fit the model\n",
    "fit2 = lm2.fit()\n",
    "\n",
    "# Check out the results\n",
    "fit2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkjtDYCoI-TT"
   },
   "source": [
    "You should see our **Adjusted R<sup>2</sup>** has increased, and our P-values are lower so we likely have a better model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBvKiLMZI-TT"
   },
   "source": [
    "**Model 3 - 2 features**\n",
    "\n",
    "Let's just try removing ***X<sub>6</sub>*** to see if that might improve our model a little bit more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UtQK0se9I-TT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model removing X6 this time\n",
    "lm3 = smf.ols('Y ~ X1 + X3', data=df)\n",
    "\n",
    "# Fit the model\n",
    "fit3 = lm3.fit()\n",
    "\n",
    "# Check out the results\n",
    "fit3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6biE3AGI-TT"
   },
   "source": [
    "Notice both **R<sup>2</sup>** coefficients decreased so let's stick with model 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "auvFsKH0I-TU"
   },
   "source": [
    "# Regression with sklearn\n",
    "Statsmodels has decent functionality for linear models, and is great for statistical summaries. But, scikit-learn has more modeling options for all sorts of algorithms as well as data preparation so it is commonly used too.\n",
    "\n",
    "### Regression with sklearn\n",
    "Before we jump into some of the additional features of sklearn, let's try to repeat our basic survey example using sklearn's built in **LinearRegression**.\n",
    "\n",
    "You should still have your Dataframe loaded from earlier.  Let's try repeating some of the different models we tried earlier with statsmodel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05o_2dgjI-TU"
   },
   "source": [
    "**Model 1 - 6 features**\n",
    "\n",
    "Here's the first model with 6 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kXbPDoHBI-TU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an empty model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Choose the predictor variables, here all but the first which is the response variable\n",
    "# This model is analogous to the Y ~ X1 + X2 + X3 + X4 + X5 + X6 model\n",
    "X = df.iloc[:, 1:]\n",
    "\n",
    "# Choose the response variable(s)\n",
    "y = df.iloc[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8G09kulQI-TU",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rb-rrdX1I-TV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZKK8hK0TI-TV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit the model to the full dataset\n",
    "lr.fit(X, y)\n",
    "\n",
    "# Print out the R^2 for the model against the full dataset\n",
    "lr.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBxMLZr0I-TV"
   },
   "source": [
    "You'll notice that this is the same **R<sup>2</sup>** value that was reported for the model 1 using statsmodels above.\n",
    "\n",
    "**Model 2 - 3 features**\n",
    "\n",
    "Let's quickly run the best model from earlier (***X1***, ***X3***, and ***X6***) and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FBF5ZiKrI-TV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an empty model\n",
    "lr1 = LinearRegression()\n",
    "\n",
    "# Choose the predictor variables, here all but the first which is the response variable\n",
    "# This model is analogous to the Y ~ X1 + X3 + X6 model\n",
    "X = df[['X1', 'X3', 'X6']]\n",
    "\n",
    "# Choose the response variable(s)\n",
    "y = df['Y']\n",
    "\n",
    "# Fit the model to the full dataset\n",
    "lr1.fit(X, y)\n",
    "\n",
    "# Print out the R^2 for the model against the full dataset\n",
    "lr1.score(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XW8OFHEKI-TV",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "adjusted_r_squared = 1 - (1-lr1.score(X, y))*(len(y)-1)/(len(y)-X.shape[1]-1)\n",
    "adjusted_r_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkZGjCBTI-TW"
   },
   "source": [
    "Notice that **R<sup>2</sup>** and adjusted **R<sup>2</sup>** are similar to what you obtained using statsmodels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8OLcM94I-TX"
   },
   "source": [
    "# Exercise 1: Car Price Predictor Dataset\n",
    "For these exercises we'll be exploring the auto data available [here](https://archive.ics.uci.edu/ml/datasets/Automobile).  The goal is to be able to predict auto price from the dataset.\n",
    "\n",
    "## Data Exploration\n",
    "Use pandas `read_csv()` to load the data into a dataframe and then call `head()` to make sure everything looks good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "px8fIFGLI-TX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read in the car dataset\n",
    "df=pd.read_csv('data/imports-85.data',header=None)\n",
    "\n",
    "columns= ['symboling','normalized-losses','make','fuel-type','aspiration','num-of-doors','body-style','drive-wheels','engine-location','wheel-base','length','width','height','curb-weight','engine-type','num-of-cylinders','engine-size','fuel-system','bore','stroke','compression-ratio','horsepower','peak-rpm','city-mpg','highway-mpg','price']\n",
    "df.columns=columns\n",
    "# Use head to view the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZhZJFgoI-TX"
   },
   "source": [
    "\n",
    "Use [`shape`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.shape.html#pandas.DataFrame.shape) to check out how many rows and columns the dataframe has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CpmywYr9I-TX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# How many rows and columns do we have?\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SozesMgjI-TX"
   },
   "source": [
    "Use [`info()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html#pandas.DataFrame.info) to get a summary of the dataframe and its datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iGRZmmQfI-TY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's examine the datatypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58nw-ud9I-TY"
   },
   "source": [
    "**Lets keep numeric data from wheel-base onwards to price**\n",
    "- Create a list of columns to keep\n",
    "- Select out only those columns from the dataframe and reassign the dataframe to that selection\n",
    "- Use `head()` & `info()` to make sure everything worked as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4gBWVu9-I-TY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a list of columns to keep\n",
    "\n",
    "subset=['wheel-base','length','width','height','curb-weight',\n",
    "        'engine-size','bore','stroke','compression-ratio','horsepower','peak-rpm','city-mpg','highway-mpg','price']\n",
    "cars=df.loc[:,subset]\n",
    "\n",
    "cars.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVo6N7vGI-TY"
   },
   "source": [
    "It looks like some of our features (bore, stroke, horsepower, peak-rpm and price) are listed as objects and not float64 or in64.\n",
    "\n",
    "Run cars.head(10), and we will see why!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQO6pInUI-TZ",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check data head\n",
    "cars.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65gv38BpI-TZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print lists of observations where price is ?\n",
    "cars[cars['price']=='?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2sD4Oj3I-TZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print entries with ?\n",
    "objects=['bore','stroke','horsepower','peak-rpm','price']\n",
    "for o in objects:\n",
    "    print('%s: %d' % (o, len(cars[cars[o]=='?'])))\n",
    "    display(cars[cars[o]=='?'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LX9vHV9FI-TZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace \"?\" data in order to turn our features into numerics\n",
    "\n",
    "objects=['bore','stroke','horsepower','peak-rpm','price']\n",
    "for o in objects:\n",
    "    cars[o]=cars[o].replace('?',np.nan)\n",
    "    cars[o]=cars[o].astype(float)\n",
    "\n",
    "cars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5z3TxvlI-TZ"
   },
   "source": [
    "We can see from the above output, that only a few entries were unknown in the first place.   \n",
    "\n",
    "To keep things simple for now, let's just go ahead and drop the entries that were unknown.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FBtj7HaHI-Ta",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cars.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_b7MzAjI-Ta",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cars['price'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HnWXQ_0nI-Ta",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cars['price'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QJpl3VNuI-Ta",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cars['price'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3I7KHwWSI-Ta",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cars=cars.dropna()\n",
    "len(cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50dNRQdXI-Ta"
   },
   "source": [
    "Before we begin modeling, use the [`corr()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.corr.html#pandas.DataFrame.corr) function to get a feel for the correlations among the different variables, especially with regard to 'price'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0wNg2D_XI-Ta",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cars.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsaUtEI6I-Tb"
   },
   "source": [
    "Take a look at only the 'price' column of the correlations and order it in descending order wih [`sort_values()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html#pandas.DataFrame.sort_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E1f7kx-rI-Tb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Try using seaborn heatmap for a better view\n",
    "plt.figure(figsize = (16,5))\n",
    "\n",
    "sns.heatmap(cars.corr(), cmap=\"seismic\", annot=True, vmin=-1, vmax=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7zIRHakHI-Tb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the correlations with 'price' sorted in descending order\n",
    "cars.corr()['price'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PliHffxI-Tb"
   },
   "source": [
    "You should now have a better feel for which variables might be most valuable for your model.\n",
    "> Q:  Do correlations provide the 'entire picture' of what is happening with our model?\n",
    "\n",
    "> A:  No. It can give us an idea but corrs will only provide the relationship with the response variable (all other factors being held constant)\n",
    "\n",
    "Now use ***seaborn's*** `pairplot()` function to visualise these correlations for the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Y5aOTfeI-Tb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Let's try visualizing some of these pairwise correlations with seaborn\n",
    "sns.pairplot(cars[['price','engine-size', 'curb-weight', 'horsepower', 'width', 'length', 'wheel-base','bore']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7MsausLI-Tb"
   },
   "source": [
    "## Exercise: Modeling with statsmodels\n",
    "Let's try some exploration with statsmodels.  As a first model, try creating an ordinary least squares model with statsmodels by incorporating all of the variables that had at least a .10 absolute value of correlation.\n",
    "- Create your model with the `ols()` function with the appropriate **R Formula** syntax and your dataframe\n",
    "- Fit the model\n",
    "- Print the fit summary to check out the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0r8AprF5I-Tb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's jump right in and try a model with statsmodels using all variables above .10 correlation\n",
    "# lsm = smf.ols('price~ ....', data = cars)\n",
    "\n",
    "# You might have issues with one of the features due to dash.. Fix variable names\n",
    "cars.rename(\n",
    "    inplace=True,\n",
    "    columns={\n",
    "        \"curb-weight\": \"curb_weight\",\n",
    "        'engine-size': 'engine_size',\n",
    "        'wheel-base': 'wheel_base'\n",
    "    })\n",
    "\n",
    "# this also works\n",
    "#cars.rename(columns=lambda name: name.replace(\"-\", \"_\"), inplace=True)\n",
    "\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vA5Oze4OI-Tc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fit and summarize\n",
    "lsm = smf.ols('price~ engine_size + curb_weight +horsepower + width + length + wheel_base + bore + height', data = cars)\n",
    "fit1 = lsm.fit()\n",
    "fit1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lB8x6uEOI-Tc"
   },
   "source": [
    "#### Seaborn for Exploring Distributions\n",
    "Your **R<sup>2</sup>** should be .834, which is not too bad. That means we can explain about 83.4% of the variance in price with this model.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxQsQuedI-Tc"
   },
   "source": [
    "## Improving Model ##\n",
    "\n",
    "If you remember from your lecture, we made assumptions about Linear Regression, one of which being: normal distribution of the predictor variable. Perhaps you have noticed from our pairplot above that our 'price' variable is skewed. Transform the y variable and rerun your OLS model. Are there any other variables we should transform?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ew8C1opQI-Tc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# take log of price and graph\n",
    "\n",
    "cars['log_price']=np.log(cars.price)\n",
    "# looks better\n",
    "cars.log_price.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ickGBlmII-Tc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# refit and summarize\n",
    "lsm = smf.ols('log_price~ engine_size + curb_weight +horsepower + width + length + wheel_base + bore + height', data = cars)\n",
    "fit2 = lsm.fit()\n",
    "fit2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bob26-YOI-Tc"
   },
   "source": [
    "You should see a slightly better **R<sup>2</sup>**"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [
    "FV_2hT0LI-TM",
    "auvFsKH0I-TU",
    "c8OLcM94I-TX"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
