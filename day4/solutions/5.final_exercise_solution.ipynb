{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a14028cd-85ae-493d-af64-f35112d0c53d"
   },
   "source": [
    "<img src=\"https://nyp-aicourse.s3.ap-southeast-1.amazonaws.com/agods/nyp_ago_logo.png\" width='400'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVUBYKna0eCW"
   },
   "source": [
    "# Final Exercise: Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CsAU4whZ0eCW"
   },
   "source": [
    "We will build a Linear regression model for Medical cost dataset. The dataset consists of age, sex, BMI, children, smoker and region feature, which are independent and charge as a dependent feature. We will predict individual medical costs billed by health insurance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkqYJCKJ0eCW"
   },
   "source": [
    "### Import Library and Dataset\n",
    "Now we will import couple of python library required for our analysis and import dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iVKK94Zv0eCX"
   },
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas  as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3kQ0X1Lf0eCX"
   },
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "df = pd.read_csv('../data/insurance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KOegNbPc0eCY"
   },
   "source": [
    "### Task 1: Check for missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TF9MvyMg0eCY",
    "outputId": "8af09e44-185d-41ab-9769-fc950fb68d74"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KUxB_pFT0eCY",
    "outputId": "71b174ee-e6ee-4730-98ea-3f5eaef6b046"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EpJS3sb0eCZ"
   },
   "source": [
    "### Task 2: Check the distribution of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E0Mu-m190eCZ",
    "outputId": "d15af517-bc47-4fa8-ea92-2a6e5e81357e"
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid')\n",
    "df.hist(figsize=(8,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DA6n4XIj0eCZ"
   },
   "source": [
    "### Task 3: Splitting Data into Train and Test Set\n",
    "\n",
    "Assuming we think age is key for good prediction, we want to preserve the same age distribution in our train and test samples.\n",
    "\n",
    "1. Bin the age into appropriate number the following bins \\[0, 25\\], \\[25, 35\\], \\[35, 45\\], \\[45, 55\\] and \\[55, $\\infty$\\]. \n",
    "2. Create a new column named 'age_cat' for the age categories. \n",
    "3. split the data into train test split, with 80:20 split, and with strafitied splitting on 'age_cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JMd7cjxs0eCZ",
    "outputId": "a2377eb4-b2dd-47bd-9a24-a2a91afa0f56"
   },
   "outputs": [],
   "source": [
    "df[\"age_cat\"] = pd.cut(df[\"age\"],\n",
    "                          bins=[0, 25, 35, 45, 55, np.inf],\n",
    "                          labels=[1, 2, 3, 4, 5])\n",
    "df[\"age_cat\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pi6Jw_J70eCa"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "strat_train_set, strat_test_set = train_test_split(df, shuffle=True, \n",
    "                                                   train_size=0.8,\n",
    "                                                   stratify=df['age_cat'], \n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6x40zwOr0eCa",
    "outputId": "b62ed8d5-2b01-4955-9e17-69cad57c5dd0"
   },
   "outputs": [],
   "source": [
    "strat_train_set.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ias4QfZU0eCa"
   },
   "source": [
    "### Task 4: Look for correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lEkLKo8a0eCa",
    "outputId": "f08ee029-48f4-4fdb-e809-9c9c53b49cbb"
   },
   "outputs": [],
   "source": [
    "# correlation plot\n",
    "corr_matrix = strat_train_set.corr()\n",
    "corr_matrix['charges'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WoWfo5Nb0eCa"
   },
   "source": [
    "Thier no correlation among valiables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7nr0bGu0eCa"
   },
   "source": [
    "### Task 5: Separate features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VrQ5N-350eCa"
   },
   "outputs": [],
   "source": [
    "insurance = strat_train_set.drop('charges', axis=1)\n",
    "insurance_labels = strat_train_set['charges']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzCIVzkV0eCb"
   },
   "source": [
    "### Task 6: Separate the numerical features from categorical features\n",
    "\n",
    "We have a few categorical features that we need to one-hot-encode. We also need to do scaling on the numerical features.  We want to build different transformation pipeline for these two different types of data.  So you need to first separate numerical features from categorical features. Call your new dataframes as `insurance_num` and `insurance_cat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJWxKE8p0eCb"
   },
   "outputs": [],
   "source": [
    "categorical_columns = ['sex','smoker', 'region', 'age_cat']\n",
    "insurance_num = insurance.drop(categorical_columns, axis=1)\n",
    "insurance_cat = insurance[categorical_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mqee_ags0eCb"
   },
   "source": [
    "### Task 7: Build a pipeline for numerical data\n",
    "\n",
    "Build a pipeline to do scaling for numerica data, using StandardScaler. It is also good practice to include imputer. Although we don't have any missing data in the training data (and test data), we cannot guarantee that there won't be any missing values during the live system (e.g. users may leave certain data blank)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JdEzAgx-0eCb"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "num_pipeline = make_pipeline(SimpleImputer(strategy='median'), StandardScaler())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHo-QrKI0eCc"
   },
   "source": [
    "### Task 8: Build a pipeline for categorical data \n",
    "\n",
    "Build pipeline to one-hot-encode categorical features. You need to specify sparse_output to False, so the return values will not be a sparse matrix, which make converting the output back to Dataframe difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MiuwwOFp0eCc"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_pipeline = make_pipeline(SimpleImputer(strategy='most_frequent'), OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpbMeIxB0eCd"
   },
   "source": [
    "### Task 9: Build a single combined pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3gbtzObd0eCd",
    "outputId": "4a1e007b-d687-4d66-b274-acbcf53e9e04"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = [\"age\", \"bmi\", \"children\"] \n",
    "cat_attribs = ['sex', 'smoker', 'region','age_cat']\n",
    "\n",
    "# preprocessing = make_column_transformer(\n",
    "#                     (num_pipeline, num_attribs), \n",
    "#                     (cat_pipeline, cat_attribs))\n",
    "# preprocessing\n",
    "\n",
    "from sklearn.compose import make_column_selector \n",
    "\n",
    "preprocessing = make_column_transformer(\n",
    "    (num_pipeline, make_column_selector(dtype_include=np.number)),\n",
    "    (cat_pipeline, make_column_selector(dtype_include=object)),\n",
    ")\n",
    "\n",
    "preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4tYwsfKc0eCe"
   },
   "source": [
    "### Task 10: Select a model and evaluate the model using cross validation\n",
    "\n",
    "Choose a scoring function, `r2` to cross validate your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SToQ9iS-0eCe",
    "outputId": "3d7669c3-a5ce-4892-c157-e60fd07aacdb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = make_pipeline(preprocessing, LinearRegression())\n",
    "linreg_score = cross_validate(lin_reg, \n",
    "                              insurance, \n",
    "                              insurance_labels,\n",
    "                              scoring=\"r2\", \n",
    "                              return_train_score=True,\n",
    "                              cv=5)\n",
    "\n",
    "print(\"r2 (train): \", linreg_score['train_score'])\n",
    "print(\"average train r2: \", linreg_score['train_score'].mean())\n",
    "print(\"r2 (val):\", linreg_score['test_score'])\n",
    "print(\"average val r2:\", linreg_score['test_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tv45teg10eCe"
   },
   "source": [
    "### Task 11: Evaluate final model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_VY5sSHj0eCe",
    "outputId": "e54024f9-fc27-485b-c9a3-4507f7f97103"
   },
   "outputs": [],
   "source": [
    "final_model = make_pipeline(preprocessing, LinearRegression())\n",
    "final_model.fit(insurance, insurance_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pi5_Aw9C0eCe",
    "outputId": "5d9d8288-38af-4eb6-a9d3-373836a9eed2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X_test = strat_test_set.drop(\"charges\", axis=1)\n",
    "y_test = strat_test_set[\"charges\"]\n",
    "\n",
    "final_predictions = final_model.predict(X_test)\n",
    "final_r2 = r2_score(y_test, final_predictions)\n",
    "print(final_r2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
