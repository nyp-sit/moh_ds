{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://nyp-aicourse.s3.ap-southeast-1.amazonaws.com/agods/nyp_ago_logo.png\" width='400'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_2jIVkz_ciq"
   },
   "source": [
    "# Text Classification (Sentiment Analysis) with Scikit-Learn\n",
    "\n",
    "In this lab exercise, we will learn how to perform Sentiment Analysis with Scikit-Learn, a popular Machine Learning toolkit for Classical Machine Learning. Sentiment Analysis is a Text Classification task where your model learns how to classify a paragraph or a document of text into whether it is a positive or a negative sentiment.\n",
    "\n",
    "We will explore using TF-IDF and various Classical Machine Learning algorithms such as Naive Bayes and SVM to classify whether sentiments of movie reviews are positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "URDv6NK1_J0N"
   },
   "outputs": [],
   "source": [
    "#!wget https://nyp-aicourse.s3-ap-southeast-1.amazonaws.com/aiup/day2-pm/lab1/lab1.zip\n",
    "#!unzip lab1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize   \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from functools import reduce\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCu3FO7JU8oH"
   },
   "source": [
    "## Section 1.1 - Explore Your Data\n",
    "\n",
    "Take a look at the IMDB Dataset.csv to see format of the text file that we will be using for this exercise. If you intend to use this set of Jupyter Notebooks later for your own Sentiment Analysis projects, please ensure that you collect your data in this format.\n",
    "\n",
    "There are 50,000 rows in the IMDB Dataset.csv file. We used Excel to cut out 40,000 rows and saved them into the train.csv file, and the remaining 10,000 rows, into the test.csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIgSk8KjA2sN"
   },
   "source": [
    "## Section 1.2 - Load Data from CSV\n",
    "\n",
    "Update the following code to load the training and test data from the correct CSV file path, and indicate the appropriate column names to extract the input text, and output classification label.\n",
    "\n",
    "The path to the training file should be **\"data/train.csv\"**, and the path to the test file should be **\"data/test.csv\"**. The column names to the input text and output labels can be found in the train.csv and test.csv files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_csv_file = 'datasets/train.csv'\n",
    "test_csv_file='datasets/test.csv'\n",
    "\n",
    "\n",
    "# Load up the data from the training CSV file.\n",
    "#\n",
    "print (\"Loading training data...\")\n",
    "train_data_df = pd.read_csv(train_csv_file)\n",
    "\n",
    "\n",
    "# Load up the data from the test CSV file.\n",
    "#    \n",
    "print (\"Loading test data...\")\n",
    "test_data_df = pd.read_csv(test_csv_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write some code to view the first five rows of the train and test data\n",
    "\n",
    "<details>\n",
    "    <summary>Click here to see code</summary>\n",
    "\n",
    "```python\n",
    "train_data_df.head()\n",
    "test_data_df.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#insert code here to look at train data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#insert code here to look at test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write some code to save the appropriate columns in the variables x_train, y_train, x_test and y_test\n",
    "\n",
    "<details>\n",
    "    <summary>Click here to see code</summary>\n",
    "\n",
    "```python\n",
    "x_train=train_data_df['review']\n",
    "y_train=train_data_df['sentiment']\n",
    "x_test=test_data_df['review']\n",
    "y_test=test_data_df['sentiment']\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#insert code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LMyYYay_J0T"
   },
   "source": [
    "## Section 1.3 - Create the Classical Machine Learning Text Classification Model\n",
    "\n",
    "The following creates the Classical Machine Learning model for our Text Classification task. \n",
    "\n",
    "Run the following cell to create a pipeline using Scikit-Learn libraries to tokenize (split into words) and lemmatize (convert words into root forms) before converting it into Bag-of-Words + TF-IDF counts and then passing that count into the Machine Learning model. \n",
    "\n",
    "This is how the processing pipeline for Natural Language Processing in Scikit-Learn will look like.\n",
    "\n",
    "<img src=\"https://nyp-aicourse.s3-ap-southeast-1.amazonaws.com/resources/day2-pm/scikit.PNG\" />\n",
    "\n",
    "The codes below create Naive Bayes, SVM or artificial neural network. Uncomment the appropriate section to create the model of your choice. Let's start with Naive Bayes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Naive Bayes\n",
    "text_classifier_model = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=LemmaTokenizer())),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "#SGD\n",
    "# text_classifier_model = Pipeline([\n",
    "#     ('vect', CountVectorizer(tokenizer=LemmaTokenizer())),\n",
    "#     ('tfidf', TfidfTransformer()),\n",
    "#     ('clf', SGDClassifier(verbose=1) ),\n",
    "# ])\n",
    "\n",
    "# #ANN\n",
    "# text_classifier_model = Pipeline([\n",
    "#     ('vect', CountVectorizer(tokenizer=LemmaTokenizer())),\n",
    "#     ('tfidf', TfidfTransformer()),\n",
    "#     ('clf', MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=20, random_state=1, max_iter=5, verbose=True) ),\n",
    "# ]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1.4 Training and Evaluating the Model\n",
    "\n",
    "Run the following cell to perform the training. Once the training is complete, run the next cell to evaluate the classifier. Review the results  to look at how well your model is doing. Take a look at the test data's F1 score, because it is a meaningful metric that tells us how well our model works for data that doesn't exist in the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (\"Training classifier...\")\n",
    "text_classifier_model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (\"Evaluating classifier...\")\n",
    "pred_y_train = text_classifier_model.predict(x_train)\n",
    "pred_y_test = text_classifier_model.predict(x_test)\n",
    "\n",
    "plt.figure(figsize=(20,6))  \n",
    "\n",
    "labels=['negative','positive']\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Print the first Confusion Matrix for the training data\n",
    "#\n",
    "cm = confusion_matrix(y_train, pred_y_train)\n",
    "\n",
    "cm_df = pd.DataFrame(cm, labels, labels)          \n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Confusion Matrix (Train Data)')\n",
    "sns.heatmap(cm_df, annot=True)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')        \n",
    "\n",
    "# Print the second Confusion Matrix for the test data\n",
    "#    \n",
    "cm = confusion_matrix(y_test, pred_y_test)\n",
    "\n",
    "cm_df = pd.DataFrame(cm, labels, labels)          \n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Confusion Matrix (Test Data)')\n",
    "sns.heatmap(cm_df, annot=True)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')        \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finally display the classification reports\n",
    "#\n",
    "print (\"Train Data\")\n",
    "print (\"--------------------------------------------------------\")\n",
    "print(metrics.classification_report(y_train, pred_y_train, target_names=labels))\n",
    "print (\"\")\n",
    "print (\"Test Data\")\n",
    "print (\"--------------------------------------------------------\")\n",
    "print(metrics.classification_report(y_test, pred_y_test, target_names=labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HB0Xdglg_J0b"
   },
   "source": [
    "## Section 1.5 - Saving the Model\n",
    "\n",
    "Let's save the model into a file that we can reload and use later on.\n",
    "\n",
    "Once you have run the following cell, take a look at the file in the folder. \n",
    "\n",
    "Once you have saved the model, you can head back to Step 1.3 to try and train your text classification task with another Machine Learning model, and save it using another filename.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_classifier_labels=['negative','positive']\n",
    "\n",
    "saved='models/Naive-Bayes'\n",
    "pickle.dump(text_classifier_labels, open(saved + \".labels\", \"wb\"))\n",
    "pickle.dump(text_classifier_model, open(saved, \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiQAH903_J0f"
   },
   "source": [
    "## Section 1.6 - Loading the Model \n",
    "\n",
    "Run the following cell to load your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_classifier_labels = pickle.load(open(saved + \".labels\", \"rb\"))\n",
    "text_classifier_model = pickle.load(open(saved, \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztWY-2Cq_J0h"
   },
   "source": [
    "## Section 1.7 - Testing the Model\n",
    "\n",
    "Let's try to run the following cell to test our model. When prompted for an input, enter any line of text and see what your machine learning model has classified the text as.\n",
    "\n",
    "Try also to load the Naive Bayes model, and load the SVM models and try the text classification for both models.\n",
    "\n",
    "Discuss your findings. \n",
    "\n",
    "1. Which model was more accurate based on the F1-score calculated after training?\n",
    "\n",
    "2. Do you think that the classification has been accurate when you actually tried the model?\n",
    "\n",
    "3. What else can you do to improve the accuracy of the model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HIKDiMip_J0h",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (\"Enter some text:\")\n",
    "text = input()\n",
    "print (\"You entered: %s\" % (text))\n",
    "input_text=pd.Series(text)\n",
    "result = text_classifier_model.predict(input_text)\n",
    "\n",
    "print (\"Classification result:\")\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "colab-exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "fc602e7e44b83c3583925fd77ac766cf87c9915ce53c5dc0c705dc2e8f6b010c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
